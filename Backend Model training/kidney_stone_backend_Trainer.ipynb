{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d2ba8e",
   "metadata": {},
   "source": [
    "### Import essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20da2064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import normalize\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd29557",
   "metadata": {},
   "source": [
    "### Locate the dataset directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "073bb92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = 'Kidney_Datasets/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fda10db",
   "metadata": {},
   "source": [
    "### Differentiate the datasets and traverse all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2497edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_images = os.listdir(image_directory + 'Normal/')\n",
    "stone_images = os.listdir(image_directory + 'Stone/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce39fd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "label = []\n",
    "INPUTSIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715ad6ab",
   "metadata": {},
   "source": [
    "### convert Images to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ad36dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image_name in enumerate(normal_images):\n",
    "    if(image_name.split('.')[1] == 'jpg' or 'png'): #only jpg or png images\n",
    "        image = cv2.imread(image_directory + 'Normal/' + image_name)\n",
    "        \n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((INPUTSIZE, INPUTSIZE))\n",
    "\n",
    "        dataset.append(np.array(image)) #append array of images in dataset list\n",
    "        label.append(0) #append '0' for all normal kidney images in label list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92d707c",
   "metadata": {},
   "source": [
    "### convert Images to arrays create labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d34fe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image_name in enumerate(stone_images):\n",
    "    if(image_name.split('.')[1] == 'jpg' or 'png'): #only jpg or png images\n",
    "        image = cv2.imread(image_directory + 'Stone/' + image_name)\n",
    "        \n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((INPUTSIZE, INPUTSIZE))\n",
    "\n",
    "        dataset.append(np.array(image)) #append array of images in dataset list\n",
    "        label.append(1) #append '1' for all kidney stone images in label list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dd4f08",
   "metadata": {},
   "source": [
    "### convert list format to array format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b12c5d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.array(dataset)\n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32df293e",
   "metadata": {},
   "source": [
    "### split dataset for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d4646a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(dataset, label, test_size=0.2, random_state=42)\n",
    "\n",
    "# xtrain, xtest, ytrain, ytest = train_test_split(dataset, label, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "079bb78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(960, 256, 256, 3)\n",
      "(240, 256, 256, 3)\n",
      "(960,)\n",
      "(240,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytrain.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f9ad32",
   "metadata": {},
   "source": [
    "### **normalize** the data in xtrain and xtest, where normalize is a function that likely comes from sklearn.preprocessing or a similar library.\n",
    "\n",
    "Why Normalize?\n",
    " * Avoid Bias in Features: If one feature has much larger values than others, it could dominate the model during training. Normalizing ensures that all features contribute equally.\n",
    "\n",
    " * Improved Performance: Many machine learning algorithms (such as KNN, SVM, etc.) perform better when the data is normalized because these algorithms rely on distance-based measures or optimization techniques that benefit from standardized data ranges.\n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "213d46e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = normalize(xtrain, axis=1)\n",
    "xtest = normalize(xtest, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c54ef7",
   "metadata": {},
   "source": [
    "### Build CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc41cb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Basic CNN Model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape = (INPUTSIZE, INPUTSIZE, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), kernel_initializer='he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), kernel_initializer='he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), kernel_initializer='he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256)) #corresponding to INPUTSIZE\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "############################RESNET50#################################\n",
    "# from keras.applications import ResNet50\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, GlobalAveragePooling2D\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "# # Load ResNet50 model (pre-trained on ImageNet)\n",
    "# resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(INPUTSIZE, INPUTSIZE, 3))\n",
    "\n",
    "# # Freeze the layers in the pre-trained model\n",
    "# for layer in resnet_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# # Add custom top layers for our specific task\n",
    "# model = Sequential()\n",
    "# model.add(resnet_model)\n",
    "# model.add(GlobalAveragePooling2D())\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28ae9171",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss= 'binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50b6f8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60/60 [==============================] - 110s 2s/step - loss: 0.0786 - accuracy: 0.9719 - val_loss: 3.5804e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "60/60 [==============================] - 107s 2s/step - loss: 1.2110e-04 - accuracy: 1.0000 - val_loss: 2.8771e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "60/60 [==============================] - 103s 2s/step - loss: 6.8092e-06 - accuracy: 1.0000 - val_loss: 3.5767e-08 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21eedf2f5b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain, ytrain, \n",
    "          batch_size=16, \n",
    "          verbose=1, \n",
    "          epochs=3, \n",
    "          validation_data=(xtest, ytest), \n",
    "          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c8b77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('kidney_stone_CNN2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3905bed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 8s 836ms/step - loss: 3.5767e-08 - accuracy: 1.0000\n",
      "This Model error is: 0.0% error\n",
      "This Model scores: 100.0% accuracy\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(xtest, ytest)\n",
    "print(f\"This Model error is: {round((test_loss)*100, 2)}% error\")\n",
    "print(f\"This Model scores: {round((test_acc)*100, 2)}% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b58b0c7",
   "metadata": {},
   "source": [
    "# Graph Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76582ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir='logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "hist = model.fit(xtrain, ytrain, \n",
    "          batch_size=16, \n",
    "          verbose=1, \n",
    "          epochs=3, \n",
    "          validation_data=(xtest, ytest), \n",
    "          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0d3cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71da2b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773bb962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
